{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b486180",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Import-Dataset\" data-toc-modified-id=\"Import-Dataset-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Import Dataset</a></span><ul class=\"toc-item\"><li><span><a href=\"#Panlasang-Pinoy-Dataset\" data-toc-modified-id=\"Panlasang-Pinoy-Dataset-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Panlasang Pinoy Dataset</a></span></li><li><span><a href=\"#Kawaling-Pinoy-Dataset\" data-toc-modified-id=\"Kawaling-Pinoy-Dataset-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Kawaling Pinoy Dataset</a></span></li><li><span><a href=\"#Merged-dataset\" data-toc-modified-id=\"Merged-dataset-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Merged dataset</a></span></li><li><span><a href=\"#Clean-dataset\" data-toc-modified-id=\"Clean-dataset-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Clean dataset</a></span></li></ul></li><li><span><a href=\"#Data-Cleaning\" data-toc-modified-id=\"Data-Cleaning-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Data Cleaning</a></span><ul class=\"toc-item\"><li><span><a href=\"#Tokenization,-Removing-of-digits-and-lowerized-text\" data-toc-modified-id=\"Tokenization,-Removing-of-digits-and-lowerized-text-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Tokenization, Removing of digits and lowerized text</a></span></li><li><span><a href=\"#Remove-Stopwords\" data-toc-modified-id=\"Remove-Stopwords-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Remove Stopwords</a></span></li><li><span><a href=\"#Lemmatized\" data-toc-modified-id=\"Lemmatized-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Lemmatized</a></span></li><li><span><a href=\"#Most-Common-Words\" data-toc-modified-id=\"Most-Common-Words-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Most Common Words</a></span></li><li><span><a href=\"#Additional-stopwords-based-on-the-common-words\" data-toc-modified-id=\"Additional-stopwords-based-on-the-common-words-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Additional stopwords based on the common words</a></span></li></ul></li><li><span><a href=\"#Topic-Modelling\" data-toc-modified-id=\"Topic-Modelling-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Topic Modelling</a></span><ul class=\"toc-item\"><li><span><a href=\"#LDA\" data-toc-modified-id=\"LDA-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>LDA</a></span></li><li><span><a href=\"#LSI\" data-toc-modified-id=\"LSI-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>LSI</a></span></li><li><span><a href=\"#HDP\" data-toc-modified-id=\"HDP-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>HDP</a></span></li><li><span><a href=\"#LDA-Scikit-Learn\" data-toc-modified-id=\"LDA-Scikit-Learn-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>LDA Scikit Learn</a></span></li></ul></li><li><span><a href=\"#Recommender\" data-toc-modified-id=\"Recommender-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Recommender</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54eaa506",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as  pd\n",
    "from pprint import pprint# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import spacy\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef2e2c9",
   "metadata": {},
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161144c5",
   "metadata": {},
   "source": [
    "### Panlasang Pinoy Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b93eeb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data scraped from Panlasang Pinoy\n",
    "panlasang_pinoy = pd.read_csv(\"panlasang_pinoy.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3656c5c7",
   "metadata": {},
   "source": [
    "### Kawaling Pinoy Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1ddd8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data scraped from Kawaling Pinoy\n",
    "kawaling_pinoy = pd.read_csv(\"kawaling_pinoy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2afda93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the food, ingredients and instructions columns \n",
    "panlasang_pinoy = panlasang_pinoy[['food', 'ingredients', 'instructions']]\n",
    "kawaling_pinoy = kawaling_pinoy[['food', 'ingredients', 'instructions']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1aa9965",
   "metadata": {},
   "source": [
    "### Merged dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8277ff3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge the dataset\n",
    "data = pd.concat([panlasang_pinoy, kawaling_pinoy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37ad3454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>food</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>instructions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pinoy Chicken Sopas</td>\n",
       "      <td>1 lb. rotisserie chicken shredded, 2 Knorr Chi...</td>\n",
       "      <td>Heat cooking oil in a cooking pot. Sauté onion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Popcorn Chicken and Gravy KFC Style Secret Recipe</td>\n",
       "      <td>1 lb. boneless chicken breast cubed, 1 cup coo...</td>\n",
       "      <td>Start making the popcorn chicken by combining ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Idol Cheesedog Bread Roll and Bites</td>\n",
       "      <td>12 CDO Idol Cheesedog, 2 cups all-purpose flou...</td>\n",
       "      <td>Start making the idol bites by preparing the d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Perfect Chicken Adobo on a Budget</td>\n",
       "      <td>2 lbs. chicken cut into serving pieces, 1 Knor...</td>\n",
       "      <td>Combine chicken, soy sauce, vinegar, and 5 clo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Creamy Mushroom Chicken</td>\n",
       "      <td>1 ½ lbs. chicken cut into serving pieces, 1 Kn...</td>\n",
       "      <td>Rub salt and ground black pepper all over the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                food  \\\n",
       "0                                Pinoy Chicken Sopas   \n",
       "1  Popcorn Chicken and Gravy KFC Style Secret Recipe   \n",
       "2                Idol Cheesedog Bread Roll and Bites   \n",
       "3                  Perfect Chicken Adobo on a Budget   \n",
       "4                            Creamy Mushroom Chicken   \n",
       "\n",
       "                                         ingredients  \\\n",
       "0  1 lb. rotisserie chicken shredded, 2 Knorr Chi...   \n",
       "1  1 lb. boneless chicken breast cubed, 1 cup coo...   \n",
       "2  12 CDO Idol Cheesedog, 2 cups all-purpose flou...   \n",
       "3  2 lbs. chicken cut into serving pieces, 1 Knor...   \n",
       "4  1 ½ lbs. chicken cut into serving pieces, 1 Kn...   \n",
       "\n",
       "                                        instructions  \n",
       "0  Heat cooking oil in a cooking pot. Sauté onion...  \n",
       "1  Start making the popcorn chicken by combining ...  \n",
       "2  Start making the idol bites by preparing the d...  \n",
       "3  Combine chicken, soy sauce, vinegar, and 5 clo...  \n",
       "4  Rub salt and ground black pepper all over the ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Inspect the dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "614e7bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>food</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>instructions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2418</td>\n",
       "      <td>2344</td>\n",
       "      <td>2418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2269</td>\n",
       "      <td>2339</td>\n",
       "      <td>2341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>none</td>\n",
       "      <td>7 pieces shrimp cleaned and deveined, 3 ounces...</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>74</td>\n",
       "      <td>2</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        food                                        ingredients instructions\n",
       "count   2418                                               2344         2418\n",
       "unique  2269                                               2339         2341\n",
       "top     none  7 pieces shrimp cleaned and deveined, 3 ounces...         none\n",
       "freq      74                                                  2           74"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()        #Check the number of rows per column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e4dcb1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "food             0\n",
       "ingredients     74\n",
       "instructions     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()             #There are 30 missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4230b5",
   "metadata": {},
   "source": [
    "### Clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d78e1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing the null values \n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0288aefd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>food</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>instructions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2344</td>\n",
       "      <td>2344</td>\n",
       "      <td>2344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2268</td>\n",
       "      <td>2339</td>\n",
       "      <td>2340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Homemade Pork Tocino</td>\n",
       "      <td>7 pieces shrimp cleaned and deveined, 3 ounces...</td>\n",
       "      <td>Heat oil in a wok or pan.\\nPan fry the shrimp ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        food  \\\n",
       "count                   2344   \n",
       "unique                  2268   \n",
       "top     Homemade Pork Tocino   \n",
       "freq                       3   \n",
       "\n",
       "                                              ingredients  \\\n",
       "count                                                2344   \n",
       "unique                                               2339   \n",
       "top     7 pieces shrimp cleaned and deveined, 3 ounces...   \n",
       "freq                                                    2   \n",
       "\n",
       "                                             instructions  \n",
       "count                                                2344  \n",
       "unique                                               2340  \n",
       "top     Heat oil in a wok or pan.\\nPan fry the shrimp ...  \n",
       "freq                                                    2  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()        #Check the dataset again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b78f4e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "food            0\n",
       "ingredients     0\n",
       "instructions    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()     #No null values then we can proceed to the next step. Yey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1be9f6ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>food</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>instructions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pinoy Chicken Sopas</td>\n",
       "      <td>1 lb. rotisserie chicken shredded, 2 Knorr Chi...</td>\n",
       "      <td>Heat cooking oil in a cooking pot. Sauté onion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Popcorn Chicken and Gravy KFC Style Secret Recipe</td>\n",
       "      <td>1 lb. boneless chicken breast cubed, 1 cup coo...</td>\n",
       "      <td>Start making the popcorn chicken by combining ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Idol Cheesedog Bread Roll and Bites</td>\n",
       "      <td>12 CDO Idol Cheesedog, 2 cups all-purpose flou...</td>\n",
       "      <td>Start making the idol bites by preparing the d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Perfect Chicken Adobo on a Budget</td>\n",
       "      <td>2 lbs. chicken cut into serving pieces, 1 Knor...</td>\n",
       "      <td>Combine chicken, soy sauce, vinegar, and 5 clo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Creamy Mushroom Chicken</td>\n",
       "      <td>1 ½ lbs. chicken cut into serving pieces, 1 Kn...</td>\n",
       "      <td>Rub salt and ground black pepper all over the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                food  \\\n",
       "0                                Pinoy Chicken Sopas   \n",
       "1  Popcorn Chicken and Gravy KFC Style Secret Recipe   \n",
       "2                Idol Cheesedog Bread Roll and Bites   \n",
       "3                  Perfect Chicken Adobo on a Budget   \n",
       "4                            Creamy Mushroom Chicken   \n",
       "\n",
       "                                         ingredients  \\\n",
       "0  1 lb. rotisserie chicken shredded, 2 Knorr Chi...   \n",
       "1  1 lb. boneless chicken breast cubed, 1 cup coo...   \n",
       "2  12 CDO Idol Cheesedog, 2 cups all-purpose flou...   \n",
       "3  2 lbs. chicken cut into serving pieces, 1 Knor...   \n",
       "4  1 ½ lbs. chicken cut into serving pieces, 1 Kn...   \n",
       "\n",
       "                                        instructions  \n",
       "0  Heat cooking oil in a cooking pot. Sauté onion...  \n",
       "1  Start making the popcorn chicken by combining ...  \n",
       "2  Start making the idol bites by preparing the d...  \n",
       "3  Combine chicken, soy sauce, vinegar, and 5 clo...  \n",
       "4  Rub salt and ground black pepper all over the ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08eddded",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192539da",
   "metadata": {},
   "source": [
    "We use ingredients column for our project since the recommender's input will be based on the ingredients available at their home."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e35404e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>food</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>instructions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pinoy Chicken Sopas</td>\n",
       "      <td>1 lb. rotisserie chicken shredded, 2 Knorr Chi...</td>\n",
       "      <td>Heat cooking oil in a cooking pot. Sauté onion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Popcorn Chicken and Gravy KFC Style Secret Recipe</td>\n",
       "      <td>1 lb. boneless chicken breast cubed, 1 cup coo...</td>\n",
       "      <td>Start making the popcorn chicken by combining ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Idol Cheesedog Bread Roll and Bites</td>\n",
       "      <td>12 CDO Idol Cheesedog, 2 cups all-purpose flou...</td>\n",
       "      <td>Start making the idol bites by preparing the d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Perfect Chicken Adobo on a Budget</td>\n",
       "      <td>2 lbs. chicken cut into serving pieces, 1 Knor...</td>\n",
       "      <td>Combine chicken, soy sauce, vinegar, and 5 clo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Creamy Mushroom Chicken</td>\n",
       "      <td>1 ½ lbs. chicken cut into serving pieces, 1 Kn...</td>\n",
       "      <td>Rub salt and ground black pepper all over the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>Garlic Butter Fried Frog Legs</td>\n",
       "      <td>1 lb about 3 to 4 pieces frog legs, 1 tablespo...</td>\n",
       "      <td>Rinse frog legs and pat dry.\\nIn a bowl, combi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>Tinolang Manok</td>\n",
       "      <td>1 tablespoon canola oil, 1 small onion, peeled...</td>\n",
       "      <td>In a pot over medium heat, heat oil. Add onion...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>Tilapia in Black Bean Garlic Sauce</td>\n",
       "      <td>4 (4 ounces each) tilapia fillets, salt and pe...</td>\n",
       "      <td>Wash tilapia and pat dry. Lightly season with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>Pork Adobo</td>\n",
       "      <td>2 pounds pork belly, cut into 2-inch cubes, 1 ...</td>\n",
       "      <td>In a bowl, combine pork, onions, garlic, bay l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>Sinigang na Baboy</td>\n",
       "      <td>2 pounds pork spare ribs, cut into 2-inch piec...</td>\n",
       "      <td>Rinse pork ribs and drain well.\\nIn a pot over...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2344 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  food  \\\n",
       "0                                  Pinoy Chicken Sopas   \n",
       "1    Popcorn Chicken and Gravy KFC Style Secret Recipe   \n",
       "2                  Idol Cheesedog Bread Roll and Bites   \n",
       "3                    Perfect Chicken Adobo on a Budget   \n",
       "4                              Creamy Mushroom Chicken   \n",
       "..                                                 ...   \n",
       "589                      Garlic Butter Fried Frog Legs   \n",
       "590                                     Tinolang Manok   \n",
       "591                 Tilapia in Black Bean Garlic Sauce   \n",
       "592                                         Pork Adobo   \n",
       "593                                  Sinigang na Baboy   \n",
       "\n",
       "                                           ingredients  \\\n",
       "0    1 lb. rotisserie chicken shredded, 2 Knorr Chi...   \n",
       "1    1 lb. boneless chicken breast cubed, 1 cup coo...   \n",
       "2    12 CDO Idol Cheesedog, 2 cups all-purpose flou...   \n",
       "3    2 lbs. chicken cut into serving pieces, 1 Knor...   \n",
       "4    1 ½ lbs. chicken cut into serving pieces, 1 Kn...   \n",
       "..                                                 ...   \n",
       "589  1 lb about 3 to 4 pieces frog legs, 1 tablespo...   \n",
       "590  1 tablespoon canola oil, 1 small onion, peeled...   \n",
       "591  4 (4 ounces each) tilapia fillets, salt and pe...   \n",
       "592  2 pounds pork belly, cut into 2-inch cubes, 1 ...   \n",
       "593  2 pounds pork spare ribs, cut into 2-inch piec...   \n",
       "\n",
       "                                          instructions  \n",
       "0    Heat cooking oil in a cooking pot. Sauté onion...  \n",
       "1    Start making the popcorn chicken by combining ...  \n",
       "2    Start making the idol bites by preparing the d...  \n",
       "3    Combine chicken, soy sauce, vinegar, and 5 clo...  \n",
       "4    Rub salt and ground black pepper all over the ...  \n",
       "..                                                 ...  \n",
       "589  Rinse frog legs and pat dry.\\nIn a bowl, combi...  \n",
       "590  In a pot over medium heat, heat oil. Add onion...  \n",
       "591  Wash tilapia and pat dry. Lightly season with ...  \n",
       "592  In a bowl, combine pork, onions, garlic, bay l...  \n",
       "593  Rinse pork ribs and drain well.\\nIn a pot over...  \n",
       "\n",
       "[2344 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the dataset again\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc94e2cf",
   "metadata": {},
   "source": [
    "### Tokenization, Removing of digits and lowerized text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f1b8b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp=spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    doc = nlp(text)\n",
    "    return [token.text for token in doc if token.is_alpha]\n",
    "\n",
    "data['ingredients_clean']=data['ingredients'].apply(lambda x: tokenize(x.lower()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "042d1a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>food</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>instructions</th>\n",
       "      <th>ingredients_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pinoy Chicken Sopas</td>\n",
       "      <td>1 lb. rotisserie chicken shredded, 2 Knorr Chi...</td>\n",
       "      <td>Heat cooking oil in a cooking pot. Sauté onion...</td>\n",
       "      <td>[lb, rotisserie, chicken, shredded, knorr, chi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Popcorn Chicken and Gravy KFC Style Secret Recipe</td>\n",
       "      <td>1 lb. boneless chicken breast cubed, 1 cup coo...</td>\n",
       "      <td>Start making the popcorn chicken by combining ...</td>\n",
       "      <td>[lb, boneless, chicken, breast, cubed, cup, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Idol Cheesedog Bread Roll and Bites</td>\n",
       "      <td>12 CDO Idol Cheesedog, 2 cups all-purpose flou...</td>\n",
       "      <td>Start making the idol bites by preparing the d...</td>\n",
       "      <td>[cdo, idol, cheesedog, cups, all, purpose, flo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Perfect Chicken Adobo on a Budget</td>\n",
       "      <td>2 lbs. chicken cut into serving pieces, 1 Knor...</td>\n",
       "      <td>Combine chicken, soy sauce, vinegar, and 5 clo...</td>\n",
       "      <td>[lbs, chicken, cut, into, serving, pieces, kno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Creamy Mushroom Chicken</td>\n",
       "      <td>1 ½ lbs. chicken cut into serving pieces, 1 Kn...</td>\n",
       "      <td>Rub salt and ground black pepper all over the ...</td>\n",
       "      <td>[lbs, chicken, cut, into, serving, pieces, kno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>Garlic Butter Fried Frog Legs</td>\n",
       "      <td>1 lb about 3 to 4 pieces frog legs, 1 tablespo...</td>\n",
       "      <td>Rinse frog legs and pat dry.\\nIn a bowl, combi...</td>\n",
       "      <td>[lb, about, to, pieces, frog, legs, tablespoon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>Tinolang Manok</td>\n",
       "      <td>1 tablespoon canola oil, 1 small onion, peeled...</td>\n",
       "      <td>In a pot over medium heat, heat oil. Add onion...</td>\n",
       "      <td>[tablespoon, canola, oil, small, onion, peeled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>Tilapia in Black Bean Garlic Sauce</td>\n",
       "      <td>4 (4 ounces each) tilapia fillets, salt and pe...</td>\n",
       "      <td>Wash tilapia and pat dry. Lightly season with ...</td>\n",
       "      <td>[ounces, each, tilapia, fillets, salt, and, pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>Pork Adobo</td>\n",
       "      <td>2 pounds pork belly, cut into 2-inch cubes, 1 ...</td>\n",
       "      <td>In a bowl, combine pork, onions, garlic, bay l...</td>\n",
       "      <td>[pounds, pork, belly, cut, into, inch, cubes, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>Sinigang na Baboy</td>\n",
       "      <td>2 pounds pork spare ribs, cut into 2-inch piec...</td>\n",
       "      <td>Rinse pork ribs and drain well.\\nIn a pot over...</td>\n",
       "      <td>[pounds, pork, spare, ribs, cut, into, inch, p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2344 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  food  \\\n",
       "0                                  Pinoy Chicken Sopas   \n",
       "1    Popcorn Chicken and Gravy KFC Style Secret Recipe   \n",
       "2                  Idol Cheesedog Bread Roll and Bites   \n",
       "3                    Perfect Chicken Adobo on a Budget   \n",
       "4                              Creamy Mushroom Chicken   \n",
       "..                                                 ...   \n",
       "589                      Garlic Butter Fried Frog Legs   \n",
       "590                                     Tinolang Manok   \n",
       "591                 Tilapia in Black Bean Garlic Sauce   \n",
       "592                                         Pork Adobo   \n",
       "593                                  Sinigang na Baboy   \n",
       "\n",
       "                                           ingredients  \\\n",
       "0    1 lb. rotisserie chicken shredded, 2 Knorr Chi...   \n",
       "1    1 lb. boneless chicken breast cubed, 1 cup coo...   \n",
       "2    12 CDO Idol Cheesedog, 2 cups all-purpose flou...   \n",
       "3    2 lbs. chicken cut into serving pieces, 1 Knor...   \n",
       "4    1 ½ lbs. chicken cut into serving pieces, 1 Kn...   \n",
       "..                                                 ...   \n",
       "589  1 lb about 3 to 4 pieces frog legs, 1 tablespo...   \n",
       "590  1 tablespoon canola oil, 1 small onion, peeled...   \n",
       "591  4 (4 ounces each) tilapia fillets, salt and pe...   \n",
       "592  2 pounds pork belly, cut into 2-inch cubes, 1 ...   \n",
       "593  2 pounds pork spare ribs, cut into 2-inch piec...   \n",
       "\n",
       "                                          instructions  \\\n",
       "0    Heat cooking oil in a cooking pot. Sauté onion...   \n",
       "1    Start making the popcorn chicken by combining ...   \n",
       "2    Start making the idol bites by preparing the d...   \n",
       "3    Combine chicken, soy sauce, vinegar, and 5 clo...   \n",
       "4    Rub salt and ground black pepper all over the ...   \n",
       "..                                                 ...   \n",
       "589  Rinse frog legs and pat dry.\\nIn a bowl, combi...   \n",
       "590  In a pot over medium heat, heat oil. Add onion...   \n",
       "591  Wash tilapia and pat dry. Lightly season with ...   \n",
       "592  In a bowl, combine pork, onions, garlic, bay l...   \n",
       "593  Rinse pork ribs and drain well.\\nIn a pot over...   \n",
       "\n",
       "                                     ingredients_clean  \n",
       "0    [lb, rotisserie, chicken, shredded, knorr, chi...  \n",
       "1    [lb, boneless, chicken, breast, cubed, cup, co...  \n",
       "2    [cdo, idol, cheesedog, cups, all, purpose, flo...  \n",
       "3    [lbs, chicken, cut, into, serving, pieces, kno...  \n",
       "4    [lbs, chicken, cut, into, serving, pieces, kno...  \n",
       "..                                                 ...  \n",
       "589  [lb, about, to, pieces, frog, legs, tablespoon...  \n",
       "590  [tablespoon, canola, oil, small, onion, peeled...  \n",
       "591  [ounces, each, tilapia, fillets, salt, and, pe...  \n",
       "592  [pounds, pork, belly, cut, into, inch, cubes, ...  \n",
       "593  [pounds, pork, spare, ribs, cut, into, inch, p...  \n",
       "\n",
       "[2344 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c897cb1",
   "metadata": {},
   "source": [
    "### Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bec7b87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49f43300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    text=[word for word in text if word not in stop_words]\n",
    "    return text\n",
    "\n",
    "data['ingredients_clean']=data['ingredients_clean'].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c838943e",
   "metadata": {},
   "source": [
    "### Lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d450cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer=nltk.stem.WordNetLemmatizer()\n",
    "def lemmatize_text(word_list):\n",
    "    lemmatized_output = [lemmatizer.lemmatize(w) for w in word_list]\n",
    "    return lemmatized_output\n",
    "\n",
    "data['ingredients_clean']= data['ingredients_clean'].apply(lambda x: lemmatize_text(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3270bffe",
   "metadata": {},
   "source": [
    "### Most Common Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa3e9cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "flat_list = list(itertools.chain(*list(data['ingredients_clean'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6711af87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cup', 6031), ('tablespoon', 3643), ('teaspoon', 3002), ('piece', 2424), ('pepper', 2136), ('salt', 1668), ('oil', 1648), ('chopped', 1590), ('onion', 1528), ('garlic', 1494), ('sliced', 1442), ('sauce', 1320), ('water', 1291), ('lb', 1269), ('minced', 1183), ('ground', 1109), ('peeled', 1070), ('cooking', 1005), ('medium', 924), ('taste', 889), ('black', 885), ('ounce', 822), ('clove', 822), ('sugar', 803), ('cut', 724), ('pork', 719), ('chicken', 666), ('egg', 627), ('powder', 595), ('green', 593), ('tomato', 538), ('white', 510), ('soy', 510), ('milk', 483), ('small', 483), ('crushed', 477), ('beef', 469), ('cube', 468), ('large', 443), ('pound', 439), ('fish', 428), ('red', 423), ('leaf', 421), ('flour', 389), ('butter', 366), ('inch', 358), ('cubed', 356), ('vinegar', 355), ('bell', 354), ('yellow', 352), ('ginger', 337), ('canola', 321), ('diced', 318), ('chili', 318), ('coconut', 317), ('shrimp', 316), ('carrot', 315), ('knorr', 309), ('cheese', 309), ('rice', 293), ('fresh', 292), ('dried', 284), ('broth', 257), ('bean', 256), ('cream', 255), ('thinly', 254), ('whole', 251), ('brown', 247), ('oz', 245), ('juice', 237), ('strip', 234), ('purpose', 227), ('cornstarch', 227), ('shredded', 225), ('optional', 221), ('head', 221), ('cleaned', 217), ('thumb', 208), ('lemon', 205), ('bunch', 202), ('olive', 199), ('potato', 198), ('bay', 190), ('granulated', 190), ('peppercorn', 182), ('belly', 165), ('serving', 162), ('baking', 161), ('thai', 157), ('cooked', 147), ('breast', 145), ('sweet', 145), ('banana', 143), ('tbsp', 142), ('long', 141), ('grated', 140), ('cabbage', 138), ('boneless', 138), ('oyster', 132), ('paste', 130), ('noodle', 130), ('parsley', 128), ('sesame', 128), ('beaten', 127), ('removed', 127), ('pea', 125), ('wine', 125), ('boiled', 124), ('pineapple', 123), ('seeded', 123), ('thin', 119), ('extract', 119), ('quartered', 118), ('bread', 112), ('package', 112), ('mayonnaise', 111), ('drained', 109), ('calamansi', 108), ('cheddar', 108), ('trimmed', 105), ('extra', 104), ('chinese', 104), ('vanilla', 104), ('condensed', 101), ('slice', 100), ('cored', 98), ('wedged', 96), ('liver', 95), ('scallion', 95), ('eggplant', 94), ('corn', 94), ('half', 93), ('raw', 91), ('stalk', 90), ('spinach', 90), ('fried', 89), ('mushroom', 88), ('thick', 88), ('julienned', 87), ('end', 87), ('finely', 86), ('lime', 85), ('patis', 85), ('ripe', 85), ('seasoning', 84), ('crumb', 81), ('ketchup', 80), ('frozen', 80), ('celery', 79), ('size', 79), ('mix', 79), ('length', 78), ('tsp', 78), ('sea', 78), ('sized', 76), ('julienne', 75), ('shell', 74), ('seed', 73), ('vegetable', 72), ('parmesan', 71), ('virgin', 71), ('glutinous', 71), ('pack', 70), ('meat', 70), ('chunk', 69), ('deveined', 68), ('bagoong', 67), ('flake', 67), ('liquid', 66), ('evaporated', 65), ('peanut', 65), ('baby', 65), ('okra', 63), ('melted', 62), ('choy', 62), ('salted', 62), ('annatto', 60), ('bok', 60), ('raisin', 58), ('tofu', 58), ('toasted', 58), ('shoulder', 56), ('softened', 56), ('recipe', 56), ('firm', 55), ('gram', 55), ('soda', 55), ('skinless', 55), ('can', 55), ('rom', 55), ('diluted', 54), ('cold', 53), ('fillet', 53), ('light', 53), ('wrapper', 53), ('quart', 51), ('bone', 51), ('spaghetti', 51), ('pig', 50), ('g', 50), ('crosswise', 50), ('hard', 50), ('paprika', 48), ('lemongrass', 48), ('de', 48), ('tuna', 48), ('unsalted', 47), ('ham', 47), ('pechay', 47), ('saba', 46), ('steak', 46), ('sirloin', 46), ('heavy', 46), ('canned', 45), ('hot', 45), ('squash', 45), ('bacon', 45), ('stock', 45), ('pinch', 45), ('mustard', 44), ('halved', 44), ('rib', 44), ('chop', 44), ('boiling', 44), ('siling', 44), ('lengthwise', 44), ('macaroni', 43), ('squid', 43), ('thigh', 43), ('malunggay', 42), ('yolk', 42), ('thawed', 42), ('roasted', 41), ('string', 41), ('alamang', 41), ('sweetened', 41), ('leftover', 40), ('crab', 40), ('broccoli', 40), ('dark', 40), ('pounded', 40), ('tamarind', 40), ('well', 40), ('choice', 39), ('separated', 39), ('hotdog', 38), ('basil', 38), ('panko', 38), ('sitaw', 38), ('lady', 38), ('kangkong', 38), ('relish', 38), ('worcestershire', 38), ('ice', 38), ('flat', 38), ('plum', 38), ('pickle', 37), ('sharp', 37), ('dry', 37), ('sinigang', 36), ('floret', 36), ('sour', 36), ('sausage', 36), ('elbow', 35), ('napa', 35), ('mung', 35), ('warm', 35), ('ube', 35), ('mussel', 35), ('coarse', 35), ('bias', 35), ('square', 34), ('anise', 34), ('stick', 34), ('young', 34), ('mango', 34), ('apple', 34), ('stemmed', 34), ('thyme', 33), ('breadcrumb', 33), ('salmon', 33), ('star', 33), ('uncooked', 33), ('ampalaya', 33), ('snake', 33), ('sherry', 33), ('wedge', 32), ('spread', 31), ('jackfruit', 31), ('shank', 31), ('part', 31), ('according', 31), ('instruction', 31), ('whipping', 31), ('dash', 30), ('papaya', 30), ('diagonally', 30), ('chicharon', 30), ('lechon', 30), ('chuck', 29)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "counter_of_flat_list = Counter(flat_list)\n",
    "\n",
    "print(counter_of_flat_list.most_common(300)) # print top 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da0fcfc",
   "metadata": {},
   "source": [
    "### Additional stopwords based on the common words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "00f36902",
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_stopwords = ['cup', 'tablespoon', 'teaspoon', 'piece', 'sliced', 'lb', 'medium',\n",
    "                        'taste', 'ounce', 'cooking', 'black', 'cut', 'green', 'small', 'white',\n",
    "                        'large', 'pound', 'red', 'inch', 'yellow', 'brown', 'optional', 'oz', \n",
    "                        'bunch', 'thumb', 'cleaned', 'serving', 'long', 'tbsp', 'oil', 'head', 'thinly', 'whole',\n",
    "                       'bunch', 'serving', 'removed', 'thin', 'extract', 'quartered', 'package', 'drained',\n",
    "                       'trimmed', 'extra', 'half', 'thick', 'end', 'finely', 'sized', 'sea', 'size', 'length',\n",
    "                        'tsp', 'sized', 'virgin', 'pack', 'quart', 'g', 'de', 'square', 'minced', 'sliced', \n",
    "                        'pepper', 'chopped', 'sliced', 'crushed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0b195270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def additional_lemmatize_text(text):\n",
    "    text=[word for word in text if word not in additional_stopwords]\n",
    "    return text\n",
    "\n",
    "data['ingredients_clean']= data['ingredients_clean'].apply(lambda x: additional_lemmatize_text(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f30b52",
   "metadata": {},
   "source": [
    "## Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38668423",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as  pd\n",
    "from pprint import pprint# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import spacy\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c177cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dictionary \n",
    "id2word = corpora.Dictionary(data['ingredients_clean'])  \n",
    "# Create Corpus \n",
    "texts = data['ingredients_clean']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6e226ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 2), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 3), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1)]]\n"
     ]
    }
   ],
   "source": [
    "# Term Document Frequency \n",
    "corpus = [id2word.doc2bow(text) for text in texts]  \n",
    "# View \n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3c2263d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('cabbage', 1),\n",
       "  ('carrot', 1),\n",
       "  ('celery', 1),\n",
       "  ('chicken', 2),\n",
       "  ('clove', 1),\n",
       "  ('cube', 1),\n",
       "  ('cubed', 1),\n",
       "  ('diced', 1),\n",
       "  ('elbow', 1),\n",
       "  ('evaporated', 1),\n",
       "  ('fish', 1),\n",
       "  ('garlic', 1),\n",
       "  ('ground', 1),\n",
       "  ('hotdog', 1),\n",
       "  ('knorr', 1),\n",
       "  ('macaroni', 1),\n",
       "  ('milk', 1),\n",
       "  ('minced', 3),\n",
       "  ('oil', 1),\n",
       "  ('onion', 1),\n",
       "  ('pepper', 1),\n",
       "  ('rotisserie', 1),\n",
       "  ('sauce', 1),\n",
       "  ('shredded', 1),\n",
       "  ('stalk', 1),\n",
       "  ('water', 1)]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb7c4fb",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84390ff4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m20\u001b[39m):\n\u001b[1;32m----> 2\u001b[0m     lda_model \u001b[38;5;241m=\u001b[39m \u001b[43mgensim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mldamodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLdaModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mid2word\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mid2word\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mnum_topics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mupdate_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mpasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43mper_word_topics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m# Compute Perplexity\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m#print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  \u001b[39;00m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# a measure of how good the model is. lower the better.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m# Compute Coherence Score\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     coherence_model_lda \u001b[38;5;241m=\u001b[39m CoherenceModel(model\u001b[38;5;241m=\u001b[39mlda_model, texts\u001b[38;5;241m=\u001b[39mdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mingredients_clean\u001b[39m\u001b[38;5;124m'\u001b[39m] , dictionary\u001b[38;5;241m=\u001b[39mid2word, coherence\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc_v\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\ldamodel.py:520\u001b[0m, in \u001b[0;36mLdaModel.__init__\u001b[1;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)\u001b[0m\n\u001b[0;32m    518\u001b[0m use_numpy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    519\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m--> 520\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunks_as_numpy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_numpy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_lifecycle_event(\n\u001b[0;32m    522\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreated\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    523\u001b[0m     msg\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrained \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    524\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\ldamodel.py:1005\u001b[0m, in \u001b[0;36mLdaModel.update\u001b[1;34m(self, corpus, chunksize, decay, offset, passes, update_every, eval_every, iterations, gamma_threshold, chunks_as_numpy)\u001b[0m\n\u001b[0;32m   1000\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1001\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[0;32m   1002\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPROGRESS: pass \u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m, at document #\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1003\u001b[0m         pass_, chunk_no \u001b[38;5;241m*\u001b[39m chunksize \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunk), lencorpus\n\u001b[0;32m   1004\u001b[0m     )\n\u001b[1;32m-> 1005\u001b[0m     gammat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_estep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1007\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimize_alpha:\n\u001b[0;32m   1008\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_alpha(gammat, rho())\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\ldamodel.py:767\u001b[0m, in \u001b[0;36mLdaModel.do_estep\u001b[1;34m(self, chunk, state)\u001b[0m\n\u001b[0;32m    765\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    766\u001b[0m     state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\n\u001b[1;32m--> 767\u001b[0m gamma, sstats \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollect_sstats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    768\u001b[0m state\u001b[38;5;241m.\u001b[39msstats \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m sstats\n\u001b[0;32m    769\u001b[0m state\u001b[38;5;241m.\u001b[39mnumdocs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m gamma\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# avoids calling len(chunk) on a generator\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\ldamodel.py:718\u001b[0m, in \u001b[0;36mLdaModel.inference\u001b[1;34m(self, chunk, collect_sstats)\u001b[0m\n\u001b[0;32m    714\u001b[0m lastgamma \u001b[38;5;241m=\u001b[39m gammad\n\u001b[0;32m    715\u001b[0m \u001b[38;5;66;03m# We represent phi implicitly to save memory and time.\u001b[39;00m\n\u001b[0;32m    716\u001b[0m \u001b[38;5;66;03m# Substituting the value of the optimal phi back into\u001b[39;00m\n\u001b[0;32m    717\u001b[0m \u001b[38;5;66;03m# the update for gamma gives this update. Cf. Lee&Seung 2001.\u001b[39;00m\n\u001b[1;32m--> 718\u001b[0m gammad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha \u001b[38;5;241m+\u001b[39m expElogthetad \u001b[38;5;241m*\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcts\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mphinorm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpElogbetad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    719\u001b[0m Elogthetad \u001b[38;5;241m=\u001b[39m dirichlet_expectation(gammad)\n\u001b[0;32m    720\u001b[0m expElogthetad \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(Elogthetad)\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for k in range(3,20):\n",
    "    lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                               id2word=id2word,\n",
    "                                               num_topics=k, \n",
    "                                               random_state=100,\n",
    "                                               update_every=1,\n",
    "                                               chunksize=100,\n",
    "                                               passes=10,\n",
    "                                               alpha='auto',\n",
    "                                               per_word_topics=True)\n",
    "    # Compute Perplexity\n",
    "    #print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  \n",
    "    # a measure of how good the model is. lower the better.\n",
    "\n",
    "    # Compute Coherence Score\n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=data['ingredients_clean'] , dictionary=id2word, coherence='c_v')\n",
    "    coherence_lda = coherence_model_lda.get_coherence()\n",
    "    print(f\"K: {k}, Perplexity: {lda_model.log_perplexity(corpus)}, Coherence: {coherence_model_lda.get_coherence()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca73129",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Print the keyword of topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a061a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  \n",
    "# a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data['ingredients_clean'] , dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e441e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_lda = gensimvis.prepare(lda_model, corpus, id2word)\n",
    "vis_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83fb3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.display(vis_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0640601f",
   "metadata": {},
   "source": [
    "### LSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c57173",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsimodel = gensim.models.lsimodel.LsiModel(corpus=corpus, num_topics=3, id2word=id2word)\n",
    "lsimodel.show_topics(num_topics=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff1850d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Coherence Score\n",
    "coherence_model_lsi = CoherenceModel(model=lsimodel, texts=data['ingredients_clean'], dictionary=id2word, coherence='c_v')\n",
    "coherence_lsi = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lsi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06168d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_lsi = gensimvis.prepare(lsimodel, corpus, id2word)\n",
    "vis_lsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7706e5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.display(vis_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907f532f",
   "metadata": {},
   "source": [
    "### HDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1a9a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdpmodel =  gensim.models.hdpmodel.HdpModel(corpus=corpus, id2word=id2word)\n",
    "\n",
    "model = hdpmodel.print_topics(num_topics=3, num_words=10)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1968365b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Coherence Score\n",
    "coherence_model_hdpmodel = CoherenceModel(model=model, texts=data['ingredients_clean'], dictionary=id2word, coherence='c_v')\n",
    "coherence_hdpmodel = coherence_model_hdpmodel.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_hdpmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c4a3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_hdp = gensimvis.prepare(lsimodel, corpus, id2word)\n",
    "vis_lsi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e4da3a",
   "metadata": {},
   "source": [
    "### LDA Scikit Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "84101a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for text preprocessing\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "# import vectorizers\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "# import numpy for matrix operation\n",
    "import numpy as np\n",
    "\n",
    "# import LDA from sklearn\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c4af305f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_vectorizer = TfidfVectorizer(tokenizer=lambda doc: doc, lowercase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6e131422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array from TF-IDF Vectorizer \n",
    "tf_idf_arr = tf_idf_vectorizer.fit_transform(data['ingredients_clean'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1c2af318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['according',\n",
       " 'achiote',\n",
       " 'active',\n",
       " 'added',\n",
       " 'additional',\n",
       " 'adobo',\n",
       " 'adobong',\n",
       " 'agar',\n",
       " 'ahi',\n",
       " 'air',\n",
       " 'aka',\n",
       " 'alamang',\n",
       " 'albacore',\n",
       " 'alfredo',\n",
       " 'alimango',\n",
       " 'alimasag',\n",
       " 'allspice',\n",
       " 'almejas',\n",
       " 'almond',\n",
       " 'also',\n",
       " 'alter',\n",
       " 'alternative',\n",
       " 'alugbati',\n",
       " 'aluminum',\n",
       " 'amaranth',\n",
       " 'amarillo',\n",
       " 'american',\n",
       " 'amount',\n",
       " 'ampalaya',\n",
       " 'anatto',\n",
       " 'ancho',\n",
       " 'anchovy',\n",
       " 'anisado',\n",
       " 'anise',\n",
       " 'anisette',\n",
       " 'annatto',\n",
       " 'annnato',\n",
       " 'ap',\n",
       " 'apple',\n",
       " 'approximately',\n",
       " 'arnibal',\n",
       " 'around',\n",
       " 'arrowroot',\n",
       " 'arroz',\n",
       " 'artichoke',\n",
       " 'arugula',\n",
       " 'asada',\n",
       " 'asian',\n",
       " 'asparagus',\n",
       " 'assorted',\n",
       " 'astuete',\n",
       " 'atchara',\n",
       " 'atchuete',\n",
       " 'atsuete',\n",
       " 'attached',\n",
       " 'authentic',\n",
       " 'available',\n",
       " 'avocado',\n",
       " 'baby',\n",
       " 'back',\n",
       " 'bacon',\n",
       " 'bag',\n",
       " 'bagiuo',\n",
       " 'bagnet',\n",
       " 'bago',\n",
       " 'bagoong',\n",
       " 'baguio',\n",
       " 'baked',\n",
       " 'baking',\n",
       " 'balaw',\n",
       " 'balayan',\n",
       " 'ball',\n",
       " 'balsamic',\n",
       " 'balut',\n",
       " 'bamboo',\n",
       " 'banana',\n",
       " 'bangus',\n",
       " 'banh',\n",
       " 'bar',\n",
       " 'barbecue',\n",
       " 'barbecued',\n",
       " 'barbeque',\n",
       " 'bark',\n",
       " 'base',\n",
       " 'based',\n",
       " 'basil',\n",
       " 'basting',\n",
       " 'bat',\n",
       " 'batch',\n",
       " 'bato',\n",
       " 'batuan',\n",
       " 'bay',\n",
       " 'bbq',\n",
       " 'bean',\n",
       " 'bearded',\n",
       " 'beaten',\n",
       " 'beef',\n",
       " 'beefsteak',\n",
       " 'beer',\n",
       " 'bell',\n",
       " 'belly',\n",
       " 'benzoate',\n",
       " 'best',\n",
       " 'bias',\n",
       " 'big',\n",
       " 'bigas',\n",
       " 'bihon',\n",
       " 'bilbao',\n",
       " 'bile',\n",
       " 'bilimbi',\n",
       " 'bilo',\n",
       " 'bilong',\n",
       " 'bird',\n",
       " 'biscuit',\n",
       " 'bisque',\n",
       " 'bisquick',\n",
       " 'bistek',\n",
       " 'bisugo',\n",
       " 'bit',\n",
       " 'bite',\n",
       " 'bitter',\n",
       " 'bittermelon',\n",
       " 'blackstrap',\n",
       " 'blade',\n",
       " 'blanched',\n",
       " 'blanching',\n",
       " 'blanket',\n",
       " 'blend',\n",
       " 'blender',\n",
       " 'block',\n",
       " 'blood',\n",
       " 'blossom',\n",
       " 'blue',\n",
       " 'blueberry',\n",
       " 'boil',\n",
       " 'boiled',\n",
       " 'boiler',\n",
       " 'boiling',\n",
       " 'bok',\n",
       " 'bokchoy',\n",
       " 'bola',\n",
       " 'bone',\n",
       " 'boneless',\n",
       " 'bonito',\n",
       " 'boo',\n",
       " 'bottle',\n",
       " 'bottled',\n",
       " 'bottom',\n",
       " 'bought',\n",
       " 'bouillon',\n",
       " 'boullion',\n",
       " 'bow',\n",
       " 'bowl',\n",
       " 'bowtie',\n",
       " 'box',\n",
       " 'brain',\n",
       " 'bran',\n",
       " 'brand',\n",
       " 'brandy',\n",
       " 'bratwurst',\n",
       " 'bread',\n",
       " 'breadcrumb',\n",
       " 'bream',\n",
       " 'breast',\n",
       " 'brine',\n",
       " 'brisket',\n",
       " 'broad',\n",
       " 'broccoli',\n",
       " 'broiled',\n",
       " 'broken',\n",
       " 'broth',\n",
       " 'brushed',\n",
       " 'brushing',\n",
       " 'brussels',\n",
       " 'brühe',\n",
       " 'bud',\n",
       " 'buko',\n",
       " 'bulaklak',\n",
       " 'bulalo',\n",
       " 'bulb',\n",
       " 'bulk',\n",
       " 'bullet',\n",
       " 'bun',\n",
       " 'bundle',\n",
       " 'bung',\n",
       " 'buo',\n",
       " 'burger',\n",
       " 'buto',\n",
       " 'butt',\n",
       " 'butter',\n",
       " 'buttercream',\n",
       " 'butterfish',\n",
       " 'butterflied',\n",
       " 'butterfly',\n",
       " 'buttermilk',\n",
       " 'butternut',\n",
       " 'button',\n",
       " 'buy',\n",
       " 'c',\n",
       " 'cabbage',\n",
       " 'cacao',\n",
       " 'caesar',\n",
       " 'cake',\n",
       " 'calabasa',\n",
       " 'calabaza',\n",
       " 'calamansi',\n",
       " 'calamar',\n",
       " 'calamari',\n",
       " 'calasparra',\n",
       " 'caldo',\n",
       " 'calf',\n",
       " 'called',\n",
       " 'camote',\n",
       " 'can',\n",
       " 'candy',\n",
       " 'cane',\n",
       " 'canned',\n",
       " 'cannellini',\n",
       " 'canola',\n",
       " 'cantaloupe',\n",
       " 'canton',\n",
       " 'caper',\n",
       " 'capsicum',\n",
       " 'carabao',\n",
       " 'carabeef',\n",
       " 'carajay',\n",
       " 'caramel',\n",
       " 'cardamom',\n",
       " 'carne',\n",
       " 'carrageenan',\n",
       " 'carrot',\n",
       " 'cashew',\n",
       " 'casing',\n",
       " 'cassava',\n",
       " 'caster',\n",
       " 'catfish',\n",
       " 'catsup',\n",
       " 'caught',\n",
       " 'cauliflower',\n",
       " 'cavity',\n",
       " 'cayenne',\n",
       " 'cdo',\n",
       " 'cedar',\n",
       " 'celery',\n",
       " 'cellophane',\n",
       " 'center',\n",
       " 'century',\n",
       " 'chaddar',\n",
       " 'char',\n",
       " 'charcoal',\n",
       " 'chardonnay',\n",
       " 'chasm',\n",
       " 'chayote',\n",
       " 'cheddar',\n",
       " 'cheek',\n",
       " 'cheese',\n",
       " 'cheesedog',\n",
       " 'cherrie',\n",
       " 'cherry',\n",
       " 'chestnut',\n",
       " 'chevon',\n",
       " 'chicharon',\n",
       " 'chick',\n",
       " 'chicken',\n",
       " 'chickpea',\n",
       " 'chiffonaded',\n",
       " 'chile',\n",
       " 'chili',\n",
       " 'chilies',\n",
       " 'chilled',\n",
       " 'chilli',\n",
       " 'chined',\n",
       " 'chinese',\n",
       " 'chip',\n",
       " 'chipotle',\n",
       " 'chive',\n",
       " 'choco',\n",
       " 'chocolate',\n",
       " 'choi',\n",
       " 'choice',\n",
       " 'chop',\n",
       " 'choped',\n",
       " 'choppped',\n",
       " 'chorizo',\n",
       " 'chow',\n",
       " 'choy',\n",
       " 'chuck',\n",
       " 'chunk',\n",
       " 'chunky',\n",
       " 'cibed',\n",
       " 'cibes',\n",
       " 'cider',\n",
       " 'cilantro',\n",
       " 'cinnamon',\n",
       " 'clam',\n",
       " 'clarified',\n",
       " 'classic',\n",
       " 'clear',\n",
       " 'click',\n",
       " 'clove',\n",
       " 'cloved',\n",
       " 'cluster',\n",
       " 'cm',\n",
       " 'coagulated',\n",
       " 'coarse',\n",
       " 'coarsely',\n",
       " 'coating',\n",
       " 'cob',\n",
       " 'cocktail',\n",
       " 'coco',\n",
       " 'cocoa',\n",
       " 'coconunut',\n",
       " 'coconut',\n",
       " 'cod',\n",
       " 'coffee',\n",
       " 'coil',\n",
       " 'coke',\n",
       " 'cola',\n",
       " 'colby',\n",
       " 'cold',\n",
       " 'coleslaw',\n",
       " 'collard',\n",
       " 'color',\n",
       " 'colored',\n",
       " 'coloring',\n",
       " 'colorless',\n",
       " 'colossal',\n",
       " 'combinacion',\n",
       " 'combine',\n",
       " 'combined',\n",
       " 'common',\n",
       " 'con',\n",
       " 'concentrate',\n",
       " 'concentrated',\n",
       " 'condense',\n",
       " 'condensed',\n",
       " 'confectioner',\n",
       " 'consomme',\n",
       " 'cook',\n",
       " 'cooked',\n",
       " 'cooker',\n",
       " 'cookie',\n",
       " 'cooky',\n",
       " 'cool',\n",
       " 'coolwhip',\n",
       " 'core',\n",
       " 'cored',\n",
       " 'coriander',\n",
       " 'corn',\n",
       " 'cornbread',\n",
       " 'corned',\n",
       " 'cornish',\n",
       " 'cornmeal',\n",
       " 'cornstarch',\n",
       " 'count',\n",
       " 'course',\n",
       " 'cove',\n",
       " 'cover',\n",
       " 'cow',\n",
       " 'crab',\n",
       " 'crablets',\n",
       " 'crabmeat',\n",
       " 'crabsticks',\n",
       " 'cracked',\n",
       " 'cracker',\n",
       " 'crackling',\n",
       " 'cranberry',\n",
       " 'crawfish',\n",
       " 'cream',\n",
       " 'creamy',\n",
       " 'cremini',\n",
       " 'creole',\n",
       " 'crimini',\n",
       " 'crisp',\n",
       " 'crispy',\n",
       " 'crisy',\n",
       " 'crosswise',\n",
       " 'crouton',\n",
       " 'crown',\n",
       " 'crumb',\n",
       " 'crumbled',\n",
       " 'crused',\n",
       " 'crust',\n",
       " 'cube',\n",
       " 'cubed',\n",
       " 'cucumber',\n",
       " 'cumin',\n",
       " 'cupcake',\n",
       " 'curd',\n",
       " 'curing',\n",
       " 'curly',\n",
       " 'curry',\n",
       " 'custard',\n",
       " 'cutlet',\n",
       " 'cuttlefish',\n",
       " 'daga',\n",
       " 'dahon',\n",
       " 'daikon',\n",
       " 'daing',\n",
       " 'dalag',\n",
       " 'danggit',\n",
       " 'dark',\n",
       " 'dash',\n",
       " 'dashi',\n",
       " 'date',\n",
       " 'day',\n",
       " 'dayap',\n",
       " 'deboned',\n",
       " 'deep',\n",
       " 'dehydrate',\n",
       " 'dehydrated',\n",
       " 'deli',\n",
       " 'depending',\n",
       " 'derived',\n",
       " 'desiccated',\n",
       " 'desired',\n",
       " 'detached',\n",
       " 'deveiened',\n",
       " 'deveined',\n",
       " 'diagonally',\n",
       " 'diameter',\n",
       " 'diced',\n",
       " 'different',\n",
       " 'dijon',\n",
       " 'dilaw',\n",
       " 'dilis',\n",
       " 'dilited',\n",
       " 'diliuted',\n",
       " 'dill',\n",
       " 'diluted',\n",
       " 'dinner',\n",
       " 'dip',\n",
       " 'dipping',\n",
       " 'discard',\n",
       " 'discarded',\n",
       " 'dissolved',\n",
       " 'distilled',\n",
       " 'divided',\n",
       " 'dog',\n",
       " 'dory',\n",
       " 'double',\n",
       " 'douchi',\n",
       " 'dough',\n",
       " 'dozen',\n",
       " 'dressed',\n",
       " 'dressing',\n",
       " 'dried',\n",
       " 'drink',\n",
       " 'dripping',\n",
       " 'drop',\n",
       " 'drumettes',\n",
       " 'drummettes',\n",
       " 'drumstick',\n",
       " 'dry',\n",
       " 'duck',\n",
       " 'dulce',\n",
       " 'dulong',\n",
       " 'dumpling',\n",
       " 'dungeneous',\n",
       " 'dusting',\n",
       " 'dutch',\n",
       " 'dynamite',\n",
       " 'ear',\n",
       " 'easy',\n",
       " 'edam',\n",
       " 'edamame',\n",
       " 'eddo',\n",
       " 'eden',\n",
       " 'edge',\n",
       " 'egg',\n",
       " 'eggplant',\n",
       " 'either',\n",
       " 'elbow',\n",
       " 'electric',\n",
       " 'embutido',\n",
       " 'enchilada',\n",
       " 'english',\n",
       " 'enhancer',\n",
       " 'enough',\n",
       " 'ensaladang',\n",
       " 'entire',\n",
       " 'entrails',\n",
       " 'envelope',\n",
       " 'equal',\n",
       " 'equivalent',\n",
       " 'essence',\n",
       " 'evaporated',\n",
       " 'evoo',\n",
       " 'exact',\n",
       " 'extracted',\n",
       " 'eye',\n",
       " 'f',\n",
       " 'face',\n",
       " 'fake',\n",
       " 'farfalle',\n",
       " 'fat',\n",
       " 'favorite',\n",
       " 'fennel',\n",
       " 'fermented',\n",
       " 'feta',\n",
       " 'fette',\n",
       " 'fettuccine',\n",
       " 'fiber',\n",
       " 'filet',\n",
       " 'filipino',\n",
       " 'fillet',\n",
       " 'filling',\n",
       " 'fin',\n",
       " 'fine',\n",
       " 'finger',\n",
       " 'fire',\n",
       " 'firm',\n",
       " 'fish',\n",
       " 'fit',\n",
       " 'five',\n",
       " 'flake',\n",
       " 'flaked',\n",
       " 'flan',\n",
       " 'flank',\n",
       " 'flat',\n",
       " 'flattened',\n",
       " 'flavor',\n",
       " 'flavoring',\n",
       " 'flesh',\n",
       " 'floret',\n",
       " 'floss',\n",
       " 'flour',\n",
       " 'flower',\n",
       " 'foil',\n",
       " 'food',\n",
       " 'foot',\n",
       " 'forest',\n",
       " 'four',\n",
       " 'frank',\n",
       " 'free',\n",
       " 'french',\n",
       " 'fresh',\n",
       " 'freshly',\n",
       " 'fried',\n",
       " 'frog',\n",
       " 'frosting',\n",
       " 'frozen',\n",
       " 'fruit',\n",
       " 'fry',\n",
       " 'frying',\n",
       " 'full',\n",
       " 'fully',\n",
       " 'fungus',\n",
       " 'funnel',\n",
       " 'furikake',\n",
       " 'fusilli',\n",
       " 'gabi',\n",
       " 'galangal',\n",
       " 'gallo',\n",
       " 'gallon',\n",
       " 'galunggong',\n",
       " 'game',\n",
       " 'garam',\n",
       " 'garbanzo',\n",
       " 'garlic',\n",
       " 'garnish',\n",
       " 'gata',\n",
       " 'gel',\n",
       " 'gelatin',\n",
       " 'gemelli',\n",
       " 'germany',\n",
       " 'get',\n",
       " 'gherkin',\n",
       " 'ghost',\n",
       " 'giblet',\n",
       " 'gill',\n",
       " 'gin',\n",
       " 'ginataang',\n",
       " 'ginger',\n",
       " 'giniling',\n",
       " 'ginisang',\n",
       " 'gizzard',\n",
       " 'glazed',\n",
       " 'glove',\n",
       " 'gluten',\n",
       " 'glutinous',\n",
       " 'go',\n",
       " 'goat',\n",
       " 'goatskin',\n",
       " 'gochugaru',\n",
       " 'gold',\n",
       " 'golden',\n",
       " 'good',\n",
       " 'gouda',\n",
       " 'gourd',\n",
       " 'grade',\n",
       " 'graham',\n",
       " 'grain',\n",
       " 'gram',\n",
       " 'granny',\n",
       " 'granulated',\n",
       " 'granule',\n",
       " 'grape',\n",
       " 'grass',\n",
       " 'grate',\n",
       " 'grated',\n",
       " 'gravy',\n",
       " 'grease',\n",
       " 'greasing',\n",
       " 'greek',\n",
       " 'grigio',\n",
       " 'grill',\n",
       " 'grilled',\n",
       " 'grilling',\n",
       " 'ground',\n",
       " 'grouper',\n",
       " 'guacamole',\n",
       " 'guajillo',\n",
       " 'guava',\n",
       " 'guinamos',\n",
       " 'guinamus',\n",
       " 'guisado',\n",
       " 'gulaman',\n",
       " 'gulay',\n",
       " 'gut',\n",
       " 'gutted',\n",
       " 'guyabano',\n",
       " 'gyoza',\n",
       " 'haba',\n",
       " 'habhab',\n",
       " 'halaya',\n",
       " 'halibut',\n",
       " 'halved',\n",
       " 'ham',\n",
       " 'hamburger',\n",
       " 'hamonado',\n",
       " 'hard',\n",
       " 'hardboiled',\n",
       " 'hash',\n",
       " 'hashbrown',\n",
       " 'headed',\n",
       " 'heart',\n",
       " 'heat',\n",
       " 'heated',\n",
       " 'heavy',\n",
       " 'hen',\n",
       " 'herb',\n",
       " 'heritage',\n",
       " 'hibi',\n",
       " 'hickory',\n",
       " 'high',\n",
       " 'hint',\n",
       " 'hoagie',\n",
       " 'hock',\n",
       " 'hog',\n",
       " 'hoisin',\n",
       " 'hollandaise',\n",
       " 'holy',\n",
       " 'homemade',\n",
       " 'hominy',\n",
       " 'honey',\n",
       " 'honeycomb',\n",
       " 'hong',\n",
       " 'horizontally',\n",
       " 'horse',\n",
       " 'hot',\n",
       " 'hotdog',\n",
       " 'hour',\n",
       " 'hugas',\n",
       " 'huge',\n",
       " 'hulled',\n",
       " 'husked',\n",
       " 'ice',\n",
       " 'iceberg',\n",
       " 'icing',\n",
       " 'idol',\n",
       " 'igado',\n",
       " 'ikea',\n",
       " 'imitation',\n",
       " 'inasal',\n",
       " 'indian',\n",
       " 'indicated',\n",
       " 'individual',\n",
       " 'individually',\n",
       " 'indomie',\n",
       " 'infused',\n",
       " 'ingredient',\n",
       " 'inihaw',\n",
       " 'ink',\n",
       " 'innards',\n",
       " 'inside',\n",
       " 'instant',\n",
       " 'instruction',\n",
       " 'intact',\n",
       " 'intentesines',\n",
       " 'intestine',\n",
       " 'iodized',\n",
       " 'irok',\n",
       " 'isda',\n",
       " 'island',\n",
       " 'isolate',\n",
       " 'italian',\n",
       " 'itlog',\n",
       " 'jack',\n",
       " 'jackfruit',\n",
       " 'jalapeno',\n",
       " 'jalapeño',\n",
       " 'jam',\n",
       " 'japanese',\n",
       " 'jasmin',\n",
       " 'jasmine',\n",
       " 'java',\n",
       " 'jaw',\n",
       " 'jelly',\n",
       " 'jeprox',\n",
       " 'jet',\n",
       " 'jicama',\n",
       " 'joint',\n",
       " 'jollibee',\n",
       " 'jowl',\n",
       " 'juice',\n",
       " 'juiced',\n",
       " 'juilienne',\n",
       " 'julienne',\n",
       " 'julienned',\n",
       " 'julliened',\n",
       " 'jumbo',\n",
       " 'jute',\n",
       " 'kabocha',\n",
       " 'kadyos',\n",
       " 'kaiser',\n",
       " 'kakang',\n",
       " 'kalabasa',\n",
       " 'kalamyas',\n",
       " 'kaldereta',\n",
       " 'kale',\n",
       " 'kalitiran',\n",
       " 'kamia',\n",
       " 'kamote',\n",
       " 'kang',\n",
       " 'kangkong',\n",
       " 'kani',\n",
       " 'kanin',\n",
       " 'kaong',\n",
       " 'kasim',\n",
       " 'kasubha',\n",
       " 'kawaii',\n",
       " 'kawali',\n",
       " 'kecap',\n",
       " 'kept',\n",
       " 'kernel',\n",
       " 'kesong',\n",
       " 'ketchup',\n",
       " 'kfc',\n",
       " 'kidney',\n",
       " 'kielbasa',\n",
       " 'kikiam',\n",
       " 'kikkoman',\n",
       " 'kilo',\n",
       " 'kimchi',\n",
       " 'kinchay',\n",
       " 'king',\n",
       " 'kingfish',\n",
       " 'kitchen',\n",
       " 'kiwi',\n",
       " 'kneading',\n",
       " 'knob',\n",
       " 'knorr',\n",
       " 'knot',\n",
       " 'knotted',\n",
       " 'known',\n",
       " 'knox',\n",
       " 'knuckle',\n",
       " 'kohol',\n",
       " 'kong',\n",
       " 'korean',\n",
       " 'kosher',\n",
       " 'kraft',\n",
       " 'kulitis',\n",
       " 'kung',\n",
       " 'labanos',\n",
       " 'labong',\n",
       " 'labuyo',\n",
       " 'lady',\n",
       " 'lagunitas',\n",
       " 'laing',\n",
       " 'lamb',\n",
       " 'langka',\n",
       " 'lapu',\n",
       " 'lard',\n",
       " 'lareg',\n",
       " 'lasagna',\n",
       " 'lasagne',\n",
       " 'latik',\n",
       " 'lato',\n",
       " 'laurel',\n",
       " 'lawry',\n",
       " 'leaf',\n",
       " 'lean',\n",
       " 'least',\n",
       " 'leaving',\n",
       " 'leche',\n",
       " 'lechon',\n",
       " 'leek',\n",
       " 'leftover',\n",
       " 'leg',\n",
       " 'lemon',\n",
       " 'lemongrass',\n",
       " 'lenght',\n",
       " 'lenghtwise',\n",
       " 'lengthwise',\n",
       " 'lengua',\n",
       " 'lettuce',\n",
       " 'liempo',\n",
       " 'life',\n",
       " 'light',\n",
       " 'lightly',\n",
       " 'like',\n",
       " 'lily',\n",
       " 'lime',\n",
       " 'linguine',\n",
       " 'link',\n",
       " 'liquefy',\n",
       " 'liqueur',\n",
       " 'liquid',\n",
       " 'liquor',\n",
       " 'lite',\n",
       " 'liter',\n",
       " 'little',\n",
       " 'littleneck',\n",
       " 'liver',\n",
       " 'loaf',\n",
       " 'lobster',\n",
       " 'log',\n",
       " 'loin',\n",
       " 'lomi',\n",
       " 'longanisa',\n",
       " 'longganisa',\n",
       " 'loofah',\n",
       " 'loom',\n",
       " 'louis',\n",
       " 'low',\n",
       " 'lower',\n",
       " 'lucban',\n",
       " 'lucky',\n",
       " 'luffa',\n",
       " 'luke',\n",
       " 'lukewarm',\n",
       " 'lumpia',\n",
       " 'luncheon',\n",
       " 'lung',\n",
       " 'luyang',\n",
       " 'lychee',\n",
       " 'lye',\n",
       " 'maalat',\n",
       " 'macadamia',\n",
       " 'macapuno',\n",
       " 'macaroni',\n",
       " 'mackerel',\n",
       " 'made',\n",
       " 'maggi',\n",
       " 'magic',\n",
       " 'mahi',\n",
       " 'make',\n",
       " 'making',\n",
       " 'malagkit',\n",
       " 'malunggay',\n",
       " 'mami',\n",
       " 'mandarin',\n",
       " 'mango',\n",
       " 'manila',\n",
       " 'manis',\n",
       " 'manok',\n",
       " 'manzanilla',\n",
       " 'maple',\n",
       " 'maraschino',\n",
       " 'margarine',\n",
       " 'marinade',\n",
       " 'marinara',\n",
       " 'marinated',\n",
       " 'marinating',\n",
       " 'mariscos',\n",
       " 'marrow',\n",
       " 'marshmallow',\n",
       " 'masago',\n",
       " 'masala',\n",
       " 'masentery',\n",
       " 'mashed',\n",
       " 'maskara',\n",
       " 'matchstick',\n",
       " 'mato',\n",
       " 'matoes',\n",
       " 'mature',\n",
       " 'maui',\n",
       " 'may',\n",
       " 'maya',\n",
       " 'mayo',\n",
       " 'mayonnaise',\n",
       " 'mayonnise',\n",
       " 'meal',\n",
       " 'measurement',\n",
       " 'measuring',\n",
       " 'meat',\n",
       " 'meatball',\n",
       " 'meatloaf',\n",
       " 'med',\n",
       " 'mein',\n",
       " 'melat',\n",
       " 'melon',\n",
       " 'melt',\n",
       " 'melted',\n",
       " 'melting',\n",
       " 'meringue',\n",
       " 'mexican',\n",
       " 'mi',\n",
       " 'miced',\n",
       " 'mignon',\n",
       " 'miki',\n",
       " 'mild',\n",
       " 'milk',\n",
       " 'milkfish',\n",
       " 'mince',\n",
       " 'mini',\n",
       " 'mint',\n",
       " 'minute',\n",
       " 'miracle',\n",
       " 'mirin',\n",
       " 'miso',\n",
       " 'mist',\n",
       " 'misua',\n",
       " 'miswa',\n",
       " 'mix',\n",
       " 'mixed',\n",
       " 'mixture',\n",
       " 'ml',\n",
       " 'mlk',\n",
       " 'mochico',\n",
       " 'mochiko',\n",
       " 'molasses',\n",
       " 'molo',\n",
       " 'monamon',\n",
       " 'monggo',\n",
       " 'monterey',\n",
       " 'monterrey',\n",
       " 'moonfish',\n",
       " 'mooring',\n",
       " 'morcon',\n",
       " 'moringa',\n",
       " 'moscato',\n",
       " 'mozarella',\n",
       " 'mozzarella',\n",
       " 'mr',\n",
       " 'msg',\n",
       " 'mudfish',\n",
       " 'muffin',\n",
       " 'multigrain',\n",
       " 'mung',\n",
       " 'munggo',\n",
       " 'muscovado',\n",
       " 'mushroom',\n",
       " 'mussel',\n",
       " 'mustard',\n",
       " 'na',\n",
       " 'napa',\n",
       " 'nata',\n",
       " 'native',\n",
       " 'natural',\n",
       " 'necessary',\n",
       " 'neck',\n",
       " 'nectar',\n",
       " 'needed',\n",
       " 'nestle',\n",
       " 'new',\n",
       " 'ng',\n",
       " 'nido',\n",
       " 'non',\n",
       " 'nonfat',\n",
       " 'nonstick',\n",
       " 'noodle',\n",
       " 'nori',\n",
       " 'note',\n",
       " 'nugget',\n",
       " 'nut',\n",
       " 'nutella',\n",
       " 'nutmeg',\n",
       " 'oat',\n",
       " 'odong',\n",
       " 'oelek',\n",
       " 'okra',\n",
       " 'old',\n",
       " 'olive',\n",
       " 'omelet',\n",
       " 'onchoy',\n",
       " 'one',\n",
       " 'ong',\n",
       " 'ongchoy',\n",
       " 'onion',\n",
       " 'open',\n",
       " 'opional',\n",
       " 'opo',\n",
       " 'orange',\n",
       " 'ordinary',\n",
       " 'oregano',\n",
       " 'oreo',\n",
       " 'organic',\n",
       " ...]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating vocabulary array which will represent all the corpus \n",
    "vocab_tf_idf = tf_idf_vectorizer.get_feature_names()\n",
    "\n",
    "# get the vocb list\n",
    "vocab_tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1548bb9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1650"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(len(vocab_tf_idf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ea012e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create object for the LDA class \n",
    "# Inside this class LDA: define the components:\n",
    "lda_model_5 = LatentDirichletAllocation(n_components = 5, max_iter = 20, random_state = 20)\n",
    "\n",
    "# fit transform on model on our count_vectorizer : running this will return our topics \n",
    "X_topics = lda_model_5.fit(tf_idf_arr)\n",
    "\n",
    "# .components_ gives us our topic distribution \n",
    "topic_words = lda_model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "eab0a368",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1 ['peeled' 'salt' 'tomato' 'onion' 'bell' 'garlic' 'beef' 'ground' 'olive']\n",
      "Topic 2 ['chicken' 'carrot' 'egg' 'ground' 'onion' 'salt' 'peeled' 'sauce'\n",
      " 'garlic']\n",
      "Topic 3 ['sauce' 'soy' 'vinegar' 'pork' 'garlic' 'sugar' 'water' 'salt' 'bay']\n",
      "Topic 4 ['milk' 'sugar' 'flour' 'egg' 'coconut' 'purpose' 'butter' 'baking'\n",
      " 'vanilla']\n",
      "Topic 5 ['fish' 'onion' 'ground' 'garlic' 'clove' 'water' 'shrimp' 'bean' 'tomato']\n"
     ]
    }
   ],
   "source": [
    "#  Define the number of Words that we want to print in every topic : n_top_words\n",
    "n_top_words = 10\n",
    "\n",
    "for i, topic_dist in enumerate(topic_words):\n",
    "    \n",
    "    # np.argsort to sorting an array or a list or the matrix acc to their values\n",
    "    sorted_topic_dist = np.argsort(topic_dist)\n",
    "    \n",
    "    # Next, to view the actual words present in those indexes we can make the use of the vocab created earlier\n",
    "    topic_words = np.array(vocab_tf_idf)[sorted_topic_dist]\n",
    "    \n",
    "    # so using the sorted_topic_indexes we ar extracting the words from the vocabulary\n",
    "    # obtaining topics + words\n",
    "    # this topic_words variable contains the Topics  as well as the respective words present in those Topics\n",
    "    topic_words = topic_words[:-n_top_words:-1]\n",
    "    print (\"Topic\", str(i+1), topic_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "372293df",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_topic = lda_model_5.transform(tf_idf_arr)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e747f36a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03856087, 0.78497785, 0.03739232, 0.10098738, 0.03808158],\n",
       "       [0.85879784, 0.03550006, 0.0362584 , 0.03487031, 0.03457339],\n",
       "       [0.04553188, 0.07463975, 0.04539241, 0.78939233, 0.04504363],\n",
       "       ...,\n",
       "       [0.81040407, 0.04695708, 0.04797002, 0.04666217, 0.04800666],\n",
       "       [0.04716905, 0.04661071, 0.81348943, 0.04602958, 0.04670123],\n",
       "       [0.03350587, 0.03311966, 0.03432934, 0.03274207, 0.86630306]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52757e11",
   "metadata": {},
   "source": [
    "## Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5e990d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "617f29cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "food                                                    Vegetable Okoy\n",
       "ingredients          8 ounces kalabasa, 1 piece carrot, ½ piece oni...\n",
       "instructions         Slice the kalabasa, carrot, and half of the on...\n",
       "ingredients_clean    [kalabasa, carrot, onion, malunggay, leaf, cor...\n",
       "Name: 78, dtype: object"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[78] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "45cf85a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.615, 0.131, 0.177, ..., 0.158, 0.157, 0.842]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommender1 =cosine_similarity(doc_topic[78].reshape(1, -1), doc_topic).round(3) \n",
    "recommender1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "22b1bd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#argsort returns sorted array pf indices with their values from low to high \n",
    "a = recommender1.argsort()\n",
    "\n",
    "np_a = np.fliplr(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2d148a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>food</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>instructions</th>\n",
       "      <th>ingredients_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>Beef Pares Mami Noodles Recipe</td>\n",
       "      <td>1/2 recipe for beef pares, 1 lb. round miki no...</td>\n",
       "      <td>Pour water in a pot. Add the beef neck bones. ...</td>\n",
       "      <td>[recipe, beef, pares, round, miki, noodle, sca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>Ginisang Togue Recipe</td>\n",
       "      <td>12 ounces mung bean sprout, 8 ounces tofu extr...</td>\n",
       "      <td>Fry the tofu until color turns golden brown th...</td>\n",
       "      <td>[mung, bean, sprout, tofu, firm, carrot, julie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>Misua Soup with Meatballs</td>\n",
       "      <td>1 lb. ground pork, 1 egg, 3/4 cup bread crumbs...</td>\n",
       "      <td>Make the meatballs by combining the ground por...</td>\n",
       "      <td>[ground, pork, egg, bread, crumb, patola, loof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>Beef Batchoy with Liver and Bung</td>\n",
       "      <td>1 to 1 1/2 lbs. fresh miki noodles, 2 lbs. bee...</td>\n",
       "      <td>Sliced the pork bung into serving pieces. Set ...</td>\n",
       "      <td>[fresh, miki, noodle, beef, tendon, beef, shan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>Chicken Nilaga with Kalabasa</td>\n",
       "      <td>2 lbs. skinless chicken thigh cut into serving...</td>\n",
       "      <td>Pour chicken broth into a cooking pot. Let boi...</td>\n",
       "      <td>[skinless, chicken, thigh, butternut, squash, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>Filipino-style Chicken Baked Macaroni</td>\n",
       "      <td>1 pound small elbow macaroni, 3 pounds chicken...</td>\n",
       "      <td>In a large pot over medium heat, bring about 4...</td>\n",
       "      <td>[elbow, macaroni, chicken, breast, thigh, meat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Filipino-style Lasagna</td>\n",
       "      <td>15 pieces uncooked lasagna noodles, 1 cup Ched...</td>\n",
       "      <td>In a large pot over medium heat, bring about 4...</td>\n",
       "      <td>[uncooked, lasagna, noodle, cheddar, jack, che...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Callos</td>\n",
       "      <td>1 pound honeycomb tripe, 1/4 cup vinegar, 3 ta...</td>\n",
       "      <td>With a knife, cut and discard any yellowish fa...</td>\n",
       "      <td>[honeycomb, tripe, vinegar, rock, salt, water,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>Baked Macaroni with Cheese Topping</td>\n",
       "      <td>1 package (16 ounces) small elbow macaroni, 1 ...</td>\n",
       "      <td>In a large pot over medium heat, bring about 4...</td>\n",
       "      <td>[elbow, macaroni, canola, filipino, style, hot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>Goto Laman Loob and Tokwat Baboy</td>\n",
       "      <td>1 cup jasmine rice, 1 cup glutinous rice, 4 qu...</td>\n",
       "      <td>Prepare the innards by boiling 2 quarts water ...</td>\n",
       "      <td>[jasmine, rice, glutinous, rice, water, knorr,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2344 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      food  \\\n",
       "697         Beef Pares Mami Noodles Recipe   \n",
       "320                  Ginisang Togue Recipe   \n",
       "932              Misua Soup with Meatballs   \n",
       "780       Beef Batchoy with Liver and Bung   \n",
       "516           Chicken Nilaga with Kalabasa   \n",
       "..                                     ...   \n",
       "409  Filipino-style Chicken Baked Macaroni   \n",
       "61                  Filipino-style Lasagna   \n",
       "145                                 Callos   \n",
       "529     Baked Macaroni with Cheese Topping   \n",
       "171       Goto Laman Loob and Tokwat Baboy   \n",
       "\n",
       "                                           ingredients  \\\n",
       "697  1/2 recipe for beef pares, 1 lb. round miki no...   \n",
       "320  12 ounces mung bean sprout, 8 ounces tofu extr...   \n",
       "932  1 lb. ground pork, 1 egg, 3/4 cup bread crumbs...   \n",
       "780  1 to 1 1/2 lbs. fresh miki noodles, 2 lbs. bee...   \n",
       "516  2 lbs. skinless chicken thigh cut into serving...   \n",
       "..                                                 ...   \n",
       "409  1 pound small elbow macaroni, 3 pounds chicken...   \n",
       "61   15 pieces uncooked lasagna noodles, 1 cup Ched...   \n",
       "145  1 pound honeycomb tripe, 1/4 cup vinegar, 3 ta...   \n",
       "529  1 package (16 ounces) small elbow macaroni, 1 ...   \n",
       "171  1 cup jasmine rice, 1 cup glutinous rice, 4 qu...   \n",
       "\n",
       "                                          instructions  \\\n",
       "697  Pour water in a pot. Add the beef neck bones. ...   \n",
       "320  Fry the tofu until color turns golden brown th...   \n",
       "932  Make the meatballs by combining the ground por...   \n",
       "780  Sliced the pork bung into serving pieces. Set ...   \n",
       "516  Pour chicken broth into a cooking pot. Let boi...   \n",
       "..                                                 ...   \n",
       "409  In a large pot over medium heat, bring about 4...   \n",
       "61   In a large pot over medium heat, bring about 4...   \n",
       "145  With a knife, cut and discard any yellowish fa...   \n",
       "529  In a large pot over medium heat, bring about 4...   \n",
       "171  Prepare the innards by boiling 2 quarts water ...   \n",
       "\n",
       "                                     ingredients_clean  \n",
       "697  [recipe, beef, pares, round, miki, noodle, sca...  \n",
       "320  [mung, bean, sprout, tofu, firm, carrot, julie...  \n",
       "932  [ground, pork, egg, bread, crumb, patola, loof...  \n",
       "780  [fresh, miki, noodle, beef, tendon, beef, shan...  \n",
       "516  [skinless, chicken, thigh, butternut, squash, ...  \n",
       "..                                                 ...  \n",
       "409  [elbow, macaroni, chicken, breast, thigh, meat...  \n",
       "61   [uncooked, lasagna, noodle, cheddar, jack, che...  \n",
       "145  [honeycomb, tripe, vinegar, rock, salt, water,...  \n",
       "529  [elbow, macaroni, canola, filipino, style, hot...  \n",
       "171  [jasmine, rice, glutinous, rice, water, knorr,...  \n",
       "\n",
       "[2344 rows x 4 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[np_a[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a449ca03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "370px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
